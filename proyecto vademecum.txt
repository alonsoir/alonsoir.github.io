Digamos que tenemos un fichero con el vademecum y lo limpio de tal forma que al final tengo un fichero asi:

#name_disease,sympton1,...,symptonN
resfriado,fiebre,dolor de cabeza,dolor muscular,fatiga,tos,congestion nasal, rinorrea,moco amarillo, moco verde, estornudos,dolor de garganta
...

Podría procesar el csv de tal manera que con un map clave valor, donde la clave es el nombre de la enfermedad y el valor es una lista o un conjunto de los sintomas.

import java.util.Set

import scala.io.Source

import spark.implicits._


def loadVademecum() = {
    
    val lines = Source.fromFile("/Users/aironman/Downloads/vademecum.txt").getLines()

    var vademecumMap = collection.mutable.Map[String,scala.collection.mutable.ListBuffer[String]]()

    var symptons =  scala.collection.mutable.ListBuffer.empty[String]

    for (line <- lines) {
       var fields = line.split(',')
       for (index <- 1 to fields.length - 1){
       		symptons :+ fields(index)
       }
       if (fields.length > 1) {
        vademecumMap += (fields(0) -> symptons)
       }
     }
    lines.close
     vademecumMap
}



val myVMMap = loadVademecum

val value = "fiebre"



scala> val values = List(1,2,3,4,5,6,7,8,9,10,1000) //List -1

scala> val factors= List(5,7) // List -2

scala> values .filter(a => factors.exists(b => a == b)) //Apply different logic for our convenience

listSymptons = List()
myVMMap.values.filter(a => factors.exists(b => a == b))

Luego, cargando en un Dataframe el VADEMECUM, podría hacer una consulta como esta para sacar el nombre de la enfermedad, incluidas las enfermedades raras.

SELECT name_disease FROM VADEMECUM WHERE symptom1 EXISTS IN list_symptons OR sympton2 EXISTS IN list_symptons OR ...;

El principal problema es, puedo convertir un Dataframe a partir de un esquema asi? 

	String, Set<String>

Y luego buscar en ese Set<String> introduciendo un numero aleatorio de sintomas?

https://www.tutorialspoint.com/scala/scala_sets.htm

https://stackoverflow.com/questions/60511927/how-to-search-data-in-a-dataframe-with-a-dynamic-schema

https://stackoverflow.com/questions/49088401/spark-from-json-with-dynamic-schema?rq=1

https://stackoverflow.com/questions/34861516/spark-replacement-for-exists-and-in/34866817

http://spark.apache.org/docs/latest/sql-getting-started.html

https://www.geeksforgeeks.org/for-loop-in-scala/

https://stackoverflow.com/questions/52588002/scala-how-to-get-the-key-of-map-where-value-as-list/52588107


Puedo resolver en Impala una consulta como la siguiente?
Asumamos que tengo datos de esta forma:
Key1,value1,value2,…,valueN
…
KeyM,value1,…,valueM

Es decir, una unica clave y un numero indeterminado de valores asociados a esa clave.

Y ahora digamos que quiero buscar claves dadas por un numero finito de valores, es decir, si proporciono value1 y value10, deberia devolverme las tuplas que tengan esos values, lo que implicaria hacer algo como

SELECT key FROM MyTABLE WHERE value1 EXISTS IN SET_VALUES OR value2 EXISTS IN SET_VALUES

Donde SET_VALUES sería ese conjunto de valores asociados a cada key y cada key puede tener un numero distinto de values.

Espero haberme explicado bien.

Puedo conseguir este tipo de consultas con Apache Impala?

Gracias